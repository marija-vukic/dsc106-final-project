{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path='/Users/adrianapsay/dsc106/dsc106-final-project/data/Wearable_Dataset'#replace the folder path \n",
    "\n",
    "strees_level_v1_path='/Users/adrianapsay/dsc106/dsc106-final-project/data/Stress_Level_v1.csv'#replace the file path\n",
    "strees_level_v2_path='/Users/adrianapsay/dsc106/dsc106-final-project/data/Stress_Level_v2.csv'#replace the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(acc_data):\n",
    "    # Initialization of variables\n",
    "    avg = 0\n",
    "    prevX, prevY, prevZ = 0, 0, 0\n",
    "    results = []\n",
    "    # Each second (32 samples) the acceleration data is summarized using the following method:\n",
    "    for i in range(0, len(acc_data), 32):\n",
    "        sum_ = 0\n",
    "        buffX = acc_data[i:i+32, 0]\n",
    "        buffY = acc_data[i:i+32, 1]\n",
    "        buffZ = acc_data[i:i+32, 2]\n",
    "        \n",
    "        for j in range(len(buffX)):\n",
    "            sum_ += max(\n",
    "                abs(buffX[j] - prevX),\n",
    "                abs(buffY[j] - prevY),\n",
    "                abs(buffZ[j] - prevZ)\n",
    "            )\n",
    "            prevX, prevY, prevZ = buffX[j], buffY[j], buffZ[j]\n",
    "        #The output is then filtered:\n",
    "        avg = avg * 0.9 + (sum_ / 32) * 0.1 #\n",
    "        results.append(avg)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_multiple(signals,timeline,subject_signals,state):\n",
    "\n",
    "    plt.figure(figsize=(25,15))\n",
    "\n",
    "    keys = list(signals[subject_signals].keys())\n",
    "    keys.remove(\"tags\")\n",
    "\n",
    "    i=1\n",
    "    \n",
    "    for key in keys:\n",
    "        plt.subplot(len(keys),1,i)\n",
    "        if i==1:\n",
    "            plt.title(subject_signals + \"  -  \"+state)\n",
    "        if key=='ACC':\n",
    "            acc=moving_average(signals[subject_signals][key])\n",
    "            plt.plot(acc,label=key)\n",
    "        else:\n",
    "            plt.plot(timeline[subject_signals][key],signals[subject_signals][key],label=key)\n",
    "        \n",
    "        for tag in signals[subject_signals][\"tags\"][1:]:\n",
    "            plt.axvline(x=tag, color='r', linestyle='-')\n",
    "\n",
    "        if state=='STRESS' and signals[subject_signals][\"tags\"]:\n",
    "            if 'S' in subject_signals: #first version\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][3], signals[subject_signals][\"tags\"][4], color='red', alpha=0.2) #stroop\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][5], signals[subject_signals][\"tags\"][6], color='red', alpha=0.2)# tmct\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][7], signals[subject_signals][\"tags\"][8], color='red', alpha=0.2)#real opinion\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][9], signals[subject_signals][\"tags\"][10], color='red', alpha=0.2)#opposite opinion\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][11], signals[subject_signals][\"tags\"][12], color='red', alpha=0.2)#subtract test\n",
    "\n",
    "            else: #second version\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][2], signals[subject_signals][\"tags\"][3], color='red', alpha=0.2) #tmct\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][4], signals[subject_signals][\"tags\"][5], color='red', alpha=0.2)#real opinion\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][6], signals[subject_signals][\"tags\"][7], color='red', alpha=0.2)#opposite opinion\n",
    "                plt.axvspan(signals[subject_signals][\"tags\"][8], signals[subject_signals][\"tags\"][9], color='red', alpha=0.2)#subtract test\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        i = i+1  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector from the data frame (signal imported by pandas)\n",
    "def create_df_array(dataframe):\n",
    "    matrix_df=dataframe.values\n",
    "    # returns 2-d matrix\n",
    "    matrix = np.array(matrix_df)\n",
    "    array_df = matrix.flatten()# Convert matrix into an array\n",
    "    return array_df\n",
    "\n",
    "# convert UTC arrays to arrays in seconds relative to 0 (record beginning)\n",
    "def time_abs_(UTC_array):\n",
    "    new_array=[]\n",
    "    for utc in UTC_array:\n",
    "        time=(datetime.datetime.strptime(utc,'%Y-%m-%d %H:%M:%S')-datetime.datetime.strptime(UTC_array[0], '%Y-%m-%d %H:%M:%S')).total_seconds()\n",
    "        new_array.append(int(time))\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_signals(main_folder):\n",
    "    signal_dict = {}\n",
    "    time_dict = {}\n",
    "    fs_dict = {}\n",
    "\n",
    "    # Get a list of subfolders in the main folder\n",
    "    subfolders = next(os.walk(main_folder))[1]\n",
    "\n",
    "    utc_start_dict={}\n",
    "    for folder_name in subfolders:\n",
    "            csv_path = f'{main_folder}/{folder_name}/EDA.csv'\n",
    "            df=pd.read_csv(csv_path)\n",
    "            utc_start_dict[folder_name]= df.columns.tolist()\n",
    "\n",
    "    # Iterate over the subfolders\n",
    "    for folder_name in subfolders:\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "        # Get a list of files in the subfolder\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        # Initialize a dictionary for the signals in the current subfolder\n",
    "        signals = {}\n",
    "        time_line = {}\n",
    "        fs_signal= {}\n",
    "        \n",
    "        # Define the list of desired file names\n",
    "        desired_files = ['EDA.csv', 'BVP.csv', 'HR.csv', 'TEMP.csv','tags.csv','ACC.csv']\n",
    "   \n",
    "        # Iterate over the files in the subfolder\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Check if it's a CSV file and if it is in the desired files list\n",
    "            if file_name.endswith('.csv') and file_name in desired_files:\n",
    "                # Read the CSV file and store the signal data\n",
    "\n",
    "                if file_name == 'tags.csv':\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path,header=None)\n",
    "                        tags_vector = create_df_array(df)\n",
    "                        tags_UTC_vector =np.insert(tags_vector,0,utc_start_dict[folder_name])\n",
    "                        signal_array=time_abs_(tags_UTC_vector)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        signal_array=[]\n",
    "                \n",
    "                else:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    fs= df.loc[0]\n",
    "                    fs=int(fs[0])# Get sampling frequency\n",
    "                    df.drop([0],axis = 0,inplace=True) \n",
    "                    signal_array = df.values\n",
    "                    time_array = np.linspace(0, len(signal_array)/fs,len(signal_array))\n",
    "\n",
    "                signal_name = file_name.split('.')[0]\n",
    "                signals[signal_name] = signal_array\n",
    "                time_line[signal_name] = time_array\n",
    "                fs_signal[signal_name] = fs\n",
    "\n",
    "        # Store the signals of the current subfolder in the main dictionary\n",
    "        signal_dict[folder_name] = signals\n",
    "        time_dict[folder_name] = time_line\n",
    "        fs_dict[folder_name] = fs_signal\n",
    "\n",
    "    return signal_dict, time_dict, fs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=os.listdir(dataset_path) #['AEROBIC', 'ANAEROBIC', 'STRESS']\n",
    "\n",
    "signal_data={}\n",
    "time_data={}\n",
    "fs_dict={}\n",
    "participants={}\n",
    "\n",
    "for state in states:\n",
    "    folder_path = f'{dataset_path}/{state}' \n",
    "    participants[state]=os.listdir(folder_path)\n",
    "    signal_data[state], time_data[state], fs_dict[state] = read_signals(folder_path) # Returns three dictionaries with subjects info: raw signals (signal_data), temporal data ready to graph (time_data) and sample frequency for escha signal(fs_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANAEROBIC', 'AEROBIC', 'STRESS'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['S05', 'S02', 'f11', 'f10', 'S03', 'S04', 'f03', 'f04', 'S17', 'S10', 'S11', 'f05', 'f02', 'S18', 'S01', 'S06', 'S08', 'f12', 'S09', 'f13', 'S07', 'f07', 'S13', 'f09', 'S14', 'S15', 'S12', 'f08', 'f01', 'f06'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_data['ANAEROBIC'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TEMP', 'tags', 'HR', 'ACC', 'EDA', 'BVP'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_data['ANAEROBIC']['S05'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[208.95],\n",
       "       [208.95],\n",
       "       [208.95],\n",
       "       ...,\n",
       "       [ 35.41],\n",
       "       [ 35.41],\n",
       "       [ 35.41]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_data['ANAEROBIC']['S05']['TEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANAEROBIC', 'AEROBIC', 'STRESS'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['S05', 'S02', 'f11', 'f10', 'S03', 'S04', 'f03', 'f04', 'S17', 'S10', 'S11', 'f05', 'f02', 'S18', 'S01', 'S06', 'S08', 'f12', 'S09', 'f13', 'S07', 'f07', 'S13', 'f09', 'S14', 'S15', 'S12', 'f08', 'f01', 'f06'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data['ANAEROBIC'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TEMP', 'tags', 'HR', 'ACC', 'EDA', 'BVP'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data['ANAEROBIC']['S05'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.50055127e-01, 5.00110254e-01, ...,\n",
       "       1.13349989e+03, 1.13374994e+03, 1.13400000e+03])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data['ANAEROBIC']['S05']['TEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANAEROBIC', 'AEROBIC', 'STRESS'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['S05', 'S02', 'f11', 'f10', 'S03', 'S04', 'f03', 'f04', 'S17', 'S10', 'S11', 'f05', 'f02', 'S18', 'S01', 'S06', 'S08', 'f12', 'S09', 'f13', 'S07', 'f07', 'S13', 'f09', 'S14', 'S15', 'S12', 'f08', 'f01', 'f06'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_dict['ANAEROBIC'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TEMP', 'tags', 'HR', 'ACC', 'EDA', 'BVP'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_dict['ANAEROBIC']['S05'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_dict['ANAEROBIC']['S05'][\"TEMP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN WITH CAUTION AS THIS IS TOO BIG LOL\n",
    "export_data = {}\n",
    "\n",
    "for state in signal_data.keys():\n",
    "    export_data[state] = {}\n",
    "\n",
    "    for subject in signal_data[state].keys():  # Iterate through subjects\n",
    "        export_data[state][subject] = {}\n",
    "\n",
    "        for signal_type in signal_data[state][subject].keys():\n",
    "            signal_values = signal_data[state][subject][signal_type]\n",
    "            timestamps = time_data[state][subject][signal_type]\n",
    "            sampling_rate = fs_dict[state][subject][signal_type]\n",
    "\n",
    "            if isinstance(signal_values, np.ndarray):  \n",
    "                signal_values = signal_values.flatten().tolist()\n",
    "            elif isinstance(signal_values, list):  \n",
    "                signal_values = [float(x) for x in signal_values]\n",
    "\n",
    "            if isinstance(timestamps, np.ndarray):  \n",
    "                timestamps = timestamps.tolist()\n",
    "            elif isinstance(timestamps, list):  \n",
    "                timestamps = [float(x) for x in timestamps]\n",
    "\n",
    "            export_data[state][subject][signal_type] = {\n",
    "                \"values\": signal_values,\n",
    "                \"timestamps\": timestamps,\n",
    "                \"sampling_rate\": int(sampling_rate)\n",
    "            }\n",
    "\n",
    "# # Save as JSON file\n",
    "# with open(\"data/wearable_data.json\", \"w\") as f:\n",
    "#     json.dump(export_data, f)\n",
    "\n",
    "# print(\"Data exported successfully to wearable_data.json!\")\n",
    "# export_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wearable_data.json\", \"w\") as json_file:\n",
    "    json.dump(export_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported successfully (MASSIVE REDUCTION)\n"
     ]
    }
   ],
   "source": [
    "export_data = {}\n",
    "\n",
    "MAX_SUBJECTS = 10\n",
    "DOWNSAMPLE_FACTOR = 100\n",
    "\n",
    "for state in signal_data.keys():\n",
    "    export_data[state] = {}\n",
    "\n",
    "    # limit subjects\n",
    "    subjects = list(signal_data[state].keys())[:MAX_SUBJECTS]\n",
    "\n",
    "    for subject in subjects:\n",
    "        export_data[state][subject] = {}\n",
    "\n",
    "        for signal_type in signal_data[state][subject].keys():\n",
    "            signal_values = signal_data[state][subject][signal_type]\n",
    "            timestamps = time_data[state][subject][signal_type]\n",
    "            sampling_rate = fs_dict[state][subject][signal_type]\n",
    "\n",
    "            if isinstance(signal_values, np.ndarray):  \n",
    "                signal_values = signal_values.flatten().tolist()\n",
    "            if isinstance(timestamps, np.ndarray):  \n",
    "                timestamps = timestamps.tolist()\n",
    "\n",
    "            # downsample\n",
    "            if len(signal_values) > 10000:\n",
    "                signal_values = signal_values[::DOWNSAMPLE_FACTOR]\n",
    "                timestamps = timestamps[::DOWNSAMPLE_FACTOR]\n",
    "\n",
    "            # store data\n",
    "            export_data[state][subject][signal_type] = {\n",
    "                \"values\": signal_values,\n",
    "                \"timestamps\": timestamps,\n",
    "                \"sampling_rate\": int(sampling_rate)\n",
    "            }\n",
    "\n",
    "with open(\"data/reduced_wearable_data.json\", \"w\") as f:\n",
    "    json.dump(export_data, f)\n",
    "\n",
    "print(\"Data exported successfully (MASSIVE REDUCTION)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
